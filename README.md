# CRAB-dev

## Name
Cosmic Rays Artificial Background (CRAB)

## Description
This project contains machine learning methods to the study of CR noise systematics in the High Frequencies Telescope (HFT) of the LiteBIRD experiment. For the data post analysis and even to identify how to reduce the noise generated by Coscmic Rays (CR), it is necessary to simulate the response in signal, generated by them in the detector, with a sample of Time Ordered Data (TOD) representative of LiteBIRD's 3-year mission. Currently, this is accomplished with a chain of Monte Carlo (MC) simulations that requires ~30 times that of the desired TOD. The aim of the code is to generate synthetic Time Ordered Data (TOD) for data augmentation, starting from Monte Carlo simulated TOD samples. The algorithm used is a Generative Adversarial Network (GAN), which has a convulutionary discriminator and a de-convolutionary generator. The code is developed in python using TensorFlow libraries to build the Neural Networks (NN).

## Project folders

The project is devided in three main folders:

- **codes**. Where are collected the Jupyter script loading and managing the data and the main code where the GAN is builded and trained.
The simple_generated_TOD code contains the implementation of the GAN, its training and performances evaluation. Its updated to use the last tested model version and can be uxecuted as a normal Jupyter Notebook. The code present the following sessions:

- Loading, check and adjustment of the data for the     neural network training.
- GAN and Wasserstein GAN class definition with the corresponding custom training steps and metrics.
- The set of the used neural networks architectures for the generator and discriminator.
- The first training phase (pre-training), where the GAN training is executed updating only the discriminator parameters keeping an untrained generator fixed.
- The second training phase, involving both the generator and the discriminator.
- The evaluation of the performances and results.

The TOD_analysis code  contatins the TOD comparison quantitative post analysis and metrics.
The complete_generated_TOD is the last version of the previous Mileston 7 simple_generated_TOD code.

- **models**. Where are collected the tested GAN models with different architectures, optimizers, hyperparameters, optimizations and training strategies. Each sub-folder correspond to a different GAN configuration and inside it there are: the trained model itself, the model summary, the plots summarizing the model performances and a generated TOD example. A deeper description of each model cuold be found in the models folder.

## Workflow

- **Milestone 6**:
The preliminary part of the project focuses on the study of the optimal machine learning algorithm to synthetically generate the TODs, which was identified to be the GAN.
A prototype of the GAN can be find in codes/naive_generated_TOD. The code development was focused on:

- The NN architectures (both generator and discriminator)
- The development of the custom training steps for the adversarial NN couple
- The test of Wasserstein and Cross Entropy discriminator loss metrics

The GAN was trained and validated on homemade generated data extrapolated from the previous studies of Tominaga and Stever (BibCode: 2022SPIE12180E..54T, arXiv: 2107.00473).

- **Milestone 7**:
The development of the GAN prototype focused on the following aspects of optimization:
    1. Custom validation metrics were implemented for both real and synthetic TODs produced by the generator. The loss metric was also changed from Weissenstein's to cross entropy. Since anomalous training was found with the Weissenstein loss.
    2. To obviate the generator domain in the network, pre-training of the discriminator alone was added by inserting a dummy random generator with fixed weights into the network.
    3. A systematic investigation of the best structure of the generator layers was carried out. Different kernel sizes of the convolutional layers, the number of filters and a deeping of the network were tested.
    4. Stabilize the GAN training, testing different optimizers and learning rates individually for the generator discriminator, weighting of the data sample and label smoothing. The best configuration results to be the Adam optimizer for the generator and SGD for the discriminator and weighting more the real TODs with respect the synthetic ones. With this configuration the discriminator keeps the accuracy reached in its pretraining and leads the NN couple during the trianing.

- **Milestone 8**:
The development of the GAN prototype focused on generation of the mission TODs sample and development of the GAN with parameters tuning on real data:
    1. Improving metrics and macro parameters monitoring the training of Generative Adversarial Network (GAN). We change the threshold with which the discriminator classifies real and synthetic generated Time Ordered Data, to increase the separation between the two and avoid spread output distribution. We also test the stability of the GAN using cross-validation on a larger dataset. We are working on implementing more macroscopic metrics with which monitor the training process and avoid unstable behaviors, together with keras tuner algorithm, which is able to perform a grid search of the hyperparameters on the NN.
    2. We tuned the neural networks of the algorithm with respect to a new sample of Monte Carlo simulated TODs. In this case the training dataset was generated simulating the energy deposit of cosmic rays on the detector wafer without the conversion in current output, which will follow straight forward with using COMSOL thermal response simulation. On this dataset we tune the training hyperparameters and optimization algorithm to stabilize the training of the two NN playing one versus the other. We tested both Wasserstein and Binary Cross Entropy metrics, different combinations of stochastic gradient descent and Adam optimizer for the generator and discriminator. Other notable tuning we implemented and tested are the label smoothing and the reduced training weights of the synthetic generated TODs with respect to the real ones. The first prevents local overfitting along the training stabilizing it. The second one brings the TODs generation to match more the real data instead of focusing on perfect synthetic-real discrimination.
    3. Generation of a wider data set to train the Generative Adversarial Network. We are merging the Geant4 simulations of the detector, which produce the energy deposit in the wafer and direct hits on the TES, with the extraction of signal for each detector channel. We also are integrating in the data set generation chain the  definitive map of the TES positions and how they are connected in samples readed by the same SQUID. This is going to allow us to have a domestic generation of the training dataset customized on our ML scope.

## References
[1] Stever, S. L., et al. ‘Simulations of Systematic Effects Arising from Cosmic Rays in the LiteBIRD Space Telescope, and Effects on the Measurements of CMB B-Modes’. Journal of Cosmology and Astroparticle Physics, vol. 2021, no. 09, IOP Publishing, Sept. 2021, p. 013, https://doi.org10.1088/1475-7516/2021/09/013.

[2] Tominaga, Mayu, et al. ‘Assessment of the Cosmic-Ray Impacts for LiteBIRD Using Geant4 Simulation’. Space Telescopes and Instrumentation 2022: Optical, Infrared, and Millimeter Wave, edited by Laura E. Coyle et al., vol. 12180, 2022, p. 1218054, https://doi.org10.1117/12.2629759. Society of Photo-Optical Instrumentation Engineers (SPIE) Conference Series.

[3] Tominaga, Mayu, et al. ‘Simulation of the Cosmic Ray Effects for the LiteBIRD Satellite Observing the CMB B-Mode Polarization’. Millimeter, Submillimeter, and Far-Infrared Detectors and Instrumentation for Astronomy X, edited by Jonas Zmuidzinas and Jian-Rong Gao, SPIE, 2020, https://doi.org10.1117/12.2576127.

## Support
Please contact us reporting any issue or for more information at email: giovanni.cavallotto@mib.infn.it.

## Project status
Tuning phase of the GAN algorithm on real data, extracted from Geant4 energy deposit Monte Carlo simulations.
Mantained and developed by Giovanni Cavallotto and Stefano Della Torre.
